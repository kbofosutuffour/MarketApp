{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from gensim.models import Word2Vec\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Product Title</th>\n",
       "      <th>Product Description</th>\n",
       "      <th>Price</th>\n",
       "      <th>Conditions</th>\n",
       "      <th>Description Length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Skin Care | Lee Posh</td>\n",
       "      <td>Lee posh Lactic Acid 60% Anti ageing Pigmenta...</td>\n",
       "      <td>PROFESSIONAL GRADE Face Peel: this peel stimul...</td>\n",
       "      <td>11.19</td>\n",
       "      <td>Very bad</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Skin Care | Generic</td>\n",
       "      <td>Generic 1 Pc brand snail eye cream remove dar...</td>\n",
       "      <td>Use: eye, item type: cream, net wt: 20g, gzzz:...</td>\n",
       "      <td>14.59</td>\n",
       "      <td>Very good</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Category                                      Product Title  \\\n",
       "0  Skin Care | Lee Posh   Lee posh Lactic Acid 60% Anti ageing Pigmenta...   \n",
       "1   Skin Care | Generic   Generic 1 Pc brand snail eye cream remove dar...   \n",
       "\n",
       "                                 Product Description  Price Conditions  \\\n",
       "0  PROFESSIONAL GRADE Face Peel: this peel stimul...  11.19   Very bad   \n",
       "1  Use: eye, item type: cream, net wt: 20g, gzzz:...  14.59  Very good   \n",
       "\n",
       "   Description Length  \n",
       "0                  47  \n",
       "1                  64  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import data\n",
    "df = pd.read_csv('preprocessed_amazon.csv')\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data\n",
    "df = pd.read_csv('preprocessed_amazon.csv')\n",
    "\n",
    "# Tokenization and Vectorization using TF-IDF\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "X_tfidf = tfidf_vectorizer.fit_transform(df['Product Description'])\n",
    "\n",
    "# Tokenization and Vectorization using Word2Vec\n",
    "tokenized_text = [word_tokenize(text) for text in df['Product Description']]\n",
    "word2vec_model = Word2Vec(sentences=tokenized_text, vector_size=100, window=5, min_count=1, sg=0)\n",
    "X_word2vec = [word2vec_model.wv[word] for word in tokenized_text]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6317      Asquith & Somerset Gardenia Flower Moisturizi...\n",
      "16771     Mystique Hills Organic Neem Flower Herbal Tea...\n",
      "7664      Ancient Flower - Natural Vitamin C and Lavend...\n",
      "16403     Ancient Flower - Natural Vitamin C and Lavend...\n",
      "468       Ancient Flower - Natural Vitamin C and Lavend...\n",
      "Name: Product Title, dtype: object\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import pandas as pd\n",
    "\n",
    "# Vectorize the product descriptions\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "X = tfidf_vectorizer.fit_transform(df['Product Description'])\n",
    "\n",
    "# Define the KNN model\n",
    "knn_model = NearestNeighbors(n_neighbors=5, metric='cosine')\n",
    "knn_model.fit(X)\n",
    "\n",
    "# Define a function to find similar posts\n",
    "def find_similar_posts(product_description, k=15):\n",
    "    # Vectorize the input product description\n",
    "    description_vector = tfidf_vectorizer.transform([product_description])\n",
    "    # Find the indices of the k nearest neighbors\n",
    "    _, indices = knn_model.kneighbors(description_vector)\n",
    "    # Return the titles of the most similar posts\n",
    "    return df.iloc[indices[0]]['Product Title']\n",
    "\n",
    "# Example usage\n",
    "input_description = \"white FLOWER\"\n",
    "similar_posts = find_similar_posts(input_description)\n",
    "print(similar_posts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similar posts using TF-IDF:\n",
      "13952     Tootsie Rolls Frooties Grape Candy (360 Count...\n",
      "7987                Tec Italy - Lumina Purple Conditioner \n",
      "2548      Storeway Nike Basic Purple EDT Deodorant Body...\n",
      "5093      60ml , purple : MSmask Travel Bottle Squeezin...\n",
      "15091     Purple : ecoLove Purple Collection Conditione...\n",
      "11987     stephblack Simple Bathing Strap with Exfoliat...\n",
      "10601     Avon Little Gold Dress Combo (EDP + Skin Soft...\n",
      "364       Reiko Flexible Long Arms Hand Free Phone Holder \n",
      "14215     ddp acrylic nail pincher tool multi function ...\n",
      "2369      Fashlady™ Green: Elecool 1 Pair Spa Gel Socks...\n",
      "4471      Lili DIY Nails Rhinestone 3D Acrylic Crystal ...\n",
      "6781      Ubervia Pack of 1 100g Multicolor Bath Ball H...\n",
      "6407      Bombshell By Victorias Secret For Women Body ...\n",
      "10195     Generic Purple, L : Yel 2 pcs Top Basketball ...\n",
      "7825      Generic Pink: pro Makeup Candy Color Moisturi...\n",
      "Name: Product Title, dtype: object\n",
      "\n",
      "Similar posts using Word2Vec:\n",
      "2643      Genuine Kart White Peel Off Nail Liquid Art L...\n",
      "1394      Genuine 6Pcs Pedicure Manicure Set Nail Care ...\n",
      "18621     Genuine 6Pcs In 1 Portable Stainless Steel Ma...\n",
      "6951      Fashlady Gray: 12 PCS Waterproof Eyebrow Penc...\n",
      "16810     Genuine 4Pcs Pedicure Manicure Set Nail Clipp...\n",
      "18209     Genuine 5Pcs Blank Tattoo Practice Skin Perma...\n",
      "9597      Genuine Tocassjo Needle Like Ceramic Nail Dri...\n",
      "10013     Genuine Xixi Sun9X 18W Uv Lamp Led Lamp For N...\n",
      "18654     Genuine 9Pcslot Pedicuremanicure Set Nail Cli...\n",
      "19413     Genuine Hot 4Pcsset Nail Clippers Scissors Fi...\n",
      "12325     Genuine 100Pcs Gold Square Acrylic Nail Art E...\n",
      "18725     Genuine 9Pcs Stainless Steel Manicure Set Nai...\n",
      "976       Genuine 4Pcsset Random Slippers Shaped Nail A...\n",
      "4187      Genuine Magical Permanent Makeup Eyebrow Rule...\n",
      "9290      Genuine 7Pcs Portable Nail Clipper Manicure S...\n",
      "Name: Product Title, dtype: object\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "import numpy as np\n",
    "\n",
    "# Fit the KNN model using TF-IDF vectors\n",
    "knn_tfidf = NearestNeighbors(n_neighbors=15, metric='cosine')\n",
    "knn_tfidf.fit(X_tfidf)\n",
    "\n",
    "# Fit the KNN model using Word2Vec vectors\n",
    "X_word2vec_array = np.array([np.mean(vec, axis=0) for vec in X_word2vec])\n",
    "knn_word2vec = NearestNeighbors(n_neighbors=15, metric='cosine')\n",
    "knn_word2vec.fit(X_word2vec_array)\n",
    "\n",
    "def find_similar_posts(input_text, vectorizer, knn_model, top_k=15):\n",
    "    if vectorizer == 'tfidf':\n",
    "        input_vector = tfidf_vectorizer.transform([input_text])\n",
    "    elif vectorizer == 'word2vec':\n",
    "        words = word_tokenize(input_text)\n",
    "        word_vectors = [word2vec_model.wv[word] for word in words if word in word2vec_model.wv]\n",
    "        if len(word_vectors) == 0:\n",
    "            return []\n",
    "        input_vector = np.mean(word_vectors, axis=0).reshape(1, -1)\n",
    "    \n",
    "    if vectorizer == 'tfidf':\n",
    "        _, indices = knn_tfidf.kneighbors(input_vector)\n",
    "    elif vectorizer == 'word2vec':\n",
    "        _, indices = knn_word2vec.kneighbors(input_vector)\n",
    "    \n",
    "    return df.iloc[indices[0]]['Product Title']\n",
    "\n",
    "# Example usage\n",
    "input_text = \"purple phonecase\"\n",
    "similar_posts_tfidf = find_similar_posts(input_text, 'tfidf', knn_tfidf)\n",
    "similar_posts_word2vec = find_similar_posts(input_text, 'word2vec', knn_word2vec)\n",
    "\n",
    "print(\"Similar posts using TF-IDF:\")\n",
    "print(similar_posts_tfidf)\n",
    "print(\"\\nSimilar posts using Word2Vec:\")\n",
    "print(similar_posts_word2vec)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'glove_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [6]\u001b[0m, in \u001b[0;36m<cell line: 38>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     35\u001b[0m     valid_vectors \u001b[38;5;241m=\u001b[39m [vec \u001b[38;5;28;01mfor\u001b[39;00m vec \u001b[38;5;129;01min\u001b[39;00m vectors \u001b[38;5;28;01mif\u001b[39;00m vec \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m]\n\u001b[0;32m     36\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mconcatenate(valid_vectors) \u001b[38;5;28;01mif\u001b[39;00m valid_vectors \u001b[38;5;28;01melse\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray([])\n\u001b[1;32m---> 38\u001b[0m X_glove_array \u001b[38;5;241m=\u001b[39m \u001b[43mget_glove_vectorized_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     39\u001b[0m knn_glove \u001b[38;5;241m=\u001b[39m NearestNeighbors(n_neighbors\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m15\u001b[39m, metric\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcosine\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     40\u001b[0m knn_glove\u001b[38;5;241m.\u001b[39mfit(X_glove_array)\n",
      "Input \u001b[1;32mIn [6]\u001b[0m, in \u001b[0;36mget_glove_vectorized_data\u001b[1;34m(X)\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_glove_vectorized_data\u001b[39m(X):\n\u001b[1;32m---> 34\u001b[0m     vectors \u001b[38;5;241m=\u001b[39m [get_mean_glove_vectors(word_tokenize(\u001b[38;5;28mstr\u001b[39m(text))) \u001b[38;5;28;01mfor\u001b[39;00m text \u001b[38;5;129;01min\u001b[39;00m X[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mProduct Title\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n\u001b[0;32m     35\u001b[0m     valid_vectors \u001b[38;5;241m=\u001b[39m [vec \u001b[38;5;28;01mfor\u001b[39;00m vec \u001b[38;5;129;01min\u001b[39;00m vectors \u001b[38;5;28;01mif\u001b[39;00m vec \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m]\n\u001b[0;32m     36\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mconcatenate(valid_vectors) \u001b[38;5;28;01mif\u001b[39;00m valid_vectors \u001b[38;5;28;01melse\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray([])\n",
      "Input \u001b[1;32mIn [6]\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_glove_vectorized_data\u001b[39m(X):\n\u001b[1;32m---> 34\u001b[0m     vectors \u001b[38;5;241m=\u001b[39m [\u001b[43mget_mean_glove_vectors\u001b[49m\u001b[43m(\u001b[49m\u001b[43mword_tokenize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m text \u001b[38;5;129;01min\u001b[39;00m X[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mProduct Title\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n\u001b[0;32m     35\u001b[0m     valid_vectors \u001b[38;5;241m=\u001b[39m [vec \u001b[38;5;28;01mfor\u001b[39;00m vec \u001b[38;5;129;01min\u001b[39;00m vectors \u001b[38;5;28;01mif\u001b[39;00m vec \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m]\n\u001b[0;32m     36\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mconcatenate(valid_vectors) \u001b[38;5;28;01mif\u001b[39;00m valid_vectors \u001b[38;5;28;01melse\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray([])\n",
      "Input \u001b[1;32mIn [6]\u001b[0m, in \u001b[0;36mget_mean_glove_vectors\u001b[1;34m(words)\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_mean_glove_vectors\u001b[39m(words):\n\u001b[1;32m---> 27\u001b[0m     vectors \u001b[38;5;241m=\u001b[39m [get_glove_vector(word) \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m words]\n\u001b[0;32m     28\u001b[0m     vectors \u001b[38;5;241m=\u001b[39m [vec \u001b[38;5;28;01mfor\u001b[39;00m vec \u001b[38;5;129;01min\u001b[39;00m vectors \u001b[38;5;28;01mif\u001b[39;00m vec \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m]\n\u001b[0;32m     29\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(vectors) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "Input \u001b[1;32mIn [6]\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_mean_glove_vectors\u001b[39m(words):\n\u001b[1;32m---> 27\u001b[0m     vectors \u001b[38;5;241m=\u001b[39m [\u001b[43mget_glove_vector\u001b[49m\u001b[43m(\u001b[49m\u001b[43mword\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m words]\n\u001b[0;32m     28\u001b[0m     vectors \u001b[38;5;241m=\u001b[39m [vec \u001b[38;5;28;01mfor\u001b[39;00m vec \u001b[38;5;129;01min\u001b[39;00m vectors \u001b[38;5;28;01mif\u001b[39;00m vec \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m]\n\u001b[0;32m     29\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(vectors) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "Input \u001b[1;32mIn [6]\u001b[0m, in \u001b[0;36mget_glove_vector\u001b[1;34m(word)\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_glove_vector\u001b[39m(word):\n\u001b[0;32m     21\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 22\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mglove_model\u001b[49m[word]\n\u001b[0;32m     23\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[0;32m     24\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'glove_model' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import numpy as np\n",
    "from nltk.tokenize import word_tokenize\n",
    "import gensim.downloader as api\n",
    "\n",
    "# # Fit the TF-IDF vectorizer\n",
    "# tfidf_vectorizer = TfidfVectorizer()\n",
    "# X_tfidf = tfidf_vectorizer.fit_transform(df)\n",
    "\n",
    "# Vectorize the product descriptions\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "X = tfidf_vectorizer.fit_transform(df['Product Description'])\n",
    "\n",
    "# Fit the KNN model using TF-IDF vectors\n",
    "knn_tfidf = NearestNeighbors(n_neighbors=15, metric='cosine')\n",
    "knn_tfidf.fit(X_tfidf)\n",
    "\n",
    "# Fit the KNN model using GloVe vectors\n",
    "def get_glove_vector(word):\n",
    "    try:\n",
    "        return glove_model[word]\n",
    "    except KeyError:\n",
    "        return None\n",
    "\n",
    "def get_mean_glove_vectors(words):\n",
    "    vectors = [get_glove_vector(word) for word in words]\n",
    "    vectors = [vec for vec in vectors if vec is not None]\n",
    "    if len(vectors) == 0:\n",
    "        return None\n",
    "    return np.mean(vectors, axis=0).reshape(1, -1)\n",
    "\n",
    "def get_glove_vectorized_data(X):\n",
    "    vectors = [get_mean_glove_vectors(word_tokenize(str(text))) for text in X['Product Title']]\n",
    "    valid_vectors = [vec for vec in vectors if vec is not None]\n",
    "    return np.concatenate(valid_vectors) if valid_vectors else np.array([])\n",
    "\n",
    "X_glove_array = get_glove_vectorized_data(df)\n",
    "knn_glove = NearestNeighbors(n_neighbors=15, metric='cosine')\n",
    "knn_glove.fit(X_glove_array)\n",
    "\n",
    "\n",
    "\n",
    "X_glove_array = get_glove_vectorized_data(df)\n",
    "knn_glove = NearestNeighbors(n_neighbors=15, metric='cosine')\n",
    "knn_glove.fit(X_glove_array)\n",
    "\n",
    "def find_similar_posts(input_text, vectorizer, knn_model, top_k=15):\n",
    "    if vectorizer == 'tfidf':\n",
    "        input_vector = tfidf_vectorizer.transform([input_text])\n",
    "    elif vectorizer == 'glove':\n",
    "        input_vector = get_mean_glove_vectors(word_tokenize(input_text))\n",
    "        if input_vector is None:\n",
    "            return []\n",
    "    \n",
    "    if vectorizer == 'tfidf':\n",
    "        _, indices = knn_tfidf.kneighbors(input_vector)\n",
    "    elif vectorizer == 'glove':\n",
    "        _, indices = knn_glove.kneighbors(input_vector)\n",
    "    \n",
    "    return df.iloc[indices[0]]['Product Title']\n",
    "\n",
    "# Example usage\n",
    "input_text = \"purple phonecase\"\n",
    "similar_posts_tfidf = find_similar_posts(input_text, 'tfidf', knn_tfidf)\n",
    "similar_posts_glove = find_similar_posts(input_text, 'glove', knn_glove)\n",
    "\n",
    "print(\"Similar posts using TF-IDF:\")\n",
    "print(similar_posts_tfidf)\n",
    "print(\"\\nSimilar posts using GloVe:\")\n",
    "print(similar_posts_glove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similar posts using TF-IDF:\n",
      " Tootsie Rolls Frooties Grape Candy (360 Count), 38.8Oz \n",
      " Tec Italy - Lumina Purple Conditioner \n",
      " Storeway Nike Basic Purple EDT Deodorant Body Spray for Women 200ml \n",
      " 60ml , purple : MSmask Travel Bottle Squeezing Bath Lotion Cosmetic Skincare Refillable None Leaking \n",
      " Purple : ecoLove Purple Collection Conditioner for colored and very dry hair - Blueberry, Grape & Lavender. 100% VEGAN (17.6 Oz) \n",
      " stephblack Simple Bathing Strap with Exfoliating Bathing Ball Back Sponge Nylon Brush Scrubbing Back Wipe(None Yellow) \n",
      " Avon Little Gold Dress Combo (EDP + Skin Softener) \n",
      " Reiko Flexible Long Arms Hand Free Phone Holder \n",
      " ddp acrylic nail pincher tool multi function cuticle pusher tweezer magic wand purple \n",
      " Fashlady™ Green: Elecool 1 Pair Spa Gel Socks Moisturize Soften Repair Cracked Skin Gel Socks Skin Moisturizing Gel Spa Socks Manicure Tools \n",
      " Lili DIY Nails Rhinestone 3D Acrylic Crystal Glitter jewelry Nail Art Decorations Makeup Tools: 036 \n",
      " Ubervia Pack of 1 100g Multicolor Bath Ball HomeBathroomBody CleanerFizzer Bath Bomb Handmade Birthday Gift Suitable For Girlfriend \n",
      " Bombshell By Victorias Secret For Women Body Lotion 8.5 oz \n",
      " Generic Purple, L : Yel 2 pcs Top Basketball Bracer Bar Lengthen Armguards Sunscreen Sports Protective Forearm Elbow Pad Sleeve Arm Warmers \n",
      " Generic Pink: pro Makeup Candy Color Moisturizing Lip Balm Natural Plant Lip Gloss Lipstick Fruit Embellish for mouth to Lip \n",
      "\n",
      "Similar posts using Word2Vec:\n",
      " Generic orange black white, Adult small : digital camo Arm Sleeve UV Sunscreen Sports Elbow baseball stitch softball stitch Elbow Support Quick Dry Basketball Arm Warmer \n",
      " Generic pink black white, Adult Xlarge : digital camo Arm Sleeve UV Sunscreen Sports Elbow baseball stitch softball stitch Elbow Support Quick Dry Basketball Arm Warmer \n",
      " Generic black gray white, Adult small : digital camo Arm Sleeve UV Sunscreen Sports Elbow baseball stitch softball stitch Elbow Support Quick Dry Basketball Arm Warmer \n",
      " Blood Red: Mapofbeauty 12 Inches/30Cm Short Straight Cosplay Costume Wig Party Wig (Blood Red) \n",
      " Linha Chronos Natura - Elixir Redutor de Rugas 15 Ml - (Natura Chronos Collection - Wrinkle Reducing Elixir 0.5 Fl Oz) \n",
      " Generic navy gray white, Adult small : digital camo Arm Sleeve UV Sunscreen Sports Elbow baseball stitch softball stitch Elbow Support Quick Dry Basketball Arm Warmer \n",
      " Genuine Kart White Peel Off Nail Liquid Art Latex Tape Easy To Clean Nail Polish Finger Skin Protected Liquid Palisade Base Coat Care 6Ml \n",
      " Fashlady Gray: 12 PCS Waterproof Eyebrow Pencil for Eyebrow Permanent Makeup Tattoo Stereotypes Pen Eyebrow Cosmetic Art \n",
      " Essential Blends Organic Amla Reetha Shikakai Bhringraj and hibicus-200GM \n",
      " UNITONE 4 white advanced ISIS Pharma \n",
      " Homely 1Pc Adjustable Tennis Elbow Support Epicondylitis Clasp Pain Relief White: L \n",
      " ORIMITE SOAP 75 GM (PACK OF 3) ANTI SCABIES SOAP \n",
      " Sinland Makeup Remover Cloth - Chemical Free - Feels Luxury Soft 15.5\" X 6.7\" 3pack \n",
      " Generic M129 : ОДНА коробка 12 цветов Nail art Украшения Супер яркий Розовый различные формы дрель Ногтей Порошок Для гель лака для ногтей Советы Z2017 \n",
      " Generic Z2020 : ОДНА коробка 12 цветов Nail art Украшения Супер яркий Розовый различные формы дрель Ногтей Порошок Для гель лака для ногтей Советы Z2017 \n",
      "\n",
      "Similar posts using GloVe:\n",
      " BeautyNeeds BORN PRETTY 6Pcs Nail Scissor Stainless Steel Nail Art Cuticle Pusher Nipper Remover Clipper Nail Brush Set Manicure Tools Kits \n",
      " DeArco Chocolatier Dearco Chocolatier Chocolate Gift Box, Rakhi Chocolate For Brother, Luxury Rakhi Gift, Premium Rakhi Gift Chocolates, Dark Chocolates, Rakhi With Chocolates, Coco Fessee, French Luxury, 20 Pieces \n",
      " MPR Foods Pasumanjal Paste 300gm \n",
      " Khadi Herbal Rose Body Wash - 210ml \n",
      " A LA MAISON FRENCH LIQ SOAP,RSMRY MNT, 16.9 FZ \n",
      " Everest Tandoori Chicken Masala, 50g \n",
      " [G9SKIN] White In Creamy Pack - 200ml \n",
      " Rakhi gifts online - 9 Chocolates Gift Box - Rakhi gifts for sister \n",
      " Burts Bees Mens Deodorant, 2.6 Ounce Units by Burts Bees \n",
      " Primal Pit Paste Natural Deodorant Lavender Pack of 2 \n",
      " Generic 5Pcs Piggy Yogurt Face Mask Moisturizing Hydrating Whitening Anti Wrinkle Anti Aging Oil Control Shrink Pore Skin Care \n",
      " Homely Carbide Nail Drill Bit Mill Cutter Grinding Head for Dead Skin Nail Polish Manicure Pedicure Machine Machine Tool 3/32 :, Q052 \n",
      " Homely STZ 21 Type Tungsten Carbide Nail Drill Bits Mills Cutter Burr Nail Files Remove Polish Manicure Nail Art Tool Accessory #01-21 : 1 \n",
      " Ed Hardy Tattoo Stick Protect UV Fade Sunscreen SPF Resistant Tanning Tan UV \n",
      " afro love shampoo 16 oz \n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import numpy as np\n",
    "from nltk.tokenize import word_tokenize\n",
    "import gensim.downloader as api\n",
    "\n",
    "# Load the GloVe model\n",
    "glove_model = api.load('glove-wiki-gigaword-100')\n",
    "\n",
    "# Vectorize the product descriptions\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "X_tfidf = tfidf_vectorizer.fit_transform(df['Product Description'])\n",
    "\n",
    "# Fit the KNN model using TF-IDF vectors\n",
    "knn_tfidf = NearestNeighbors(n_neighbors=15, metric='cosine')\n",
    "knn_tfidf.fit(X_tfidf)\n",
    "\n",
    "# Fit the KNN model using Word2Vec vectors\n",
    "X_word2vec_array = np.array([np.mean(vec, axis=0) for vec in X_word2vec])\n",
    "knn_word2vec = NearestNeighbors(n_neighbors=15, metric='cosine')\n",
    "knn_word2vec.fit(X_word2vec_array)\n",
    "\n",
    "# Fit the KNN model using GloVe vectors\n",
    "def get_glove_vector(word):\n",
    "    try:\n",
    "        return glove_model[word]\n",
    "    except KeyError:\n",
    "        return None\n",
    "\n",
    "def get_mean_glove_vectors(words):\n",
    "    vectors = [get_glove_vector(word) for word in words]\n",
    "    vectors = [vec for vec in vectors if vec is not None]\n",
    "    if len(vectors) == 0:\n",
    "        return None\n",
    "    return np.mean(vectors, axis=0).reshape(1, -1)\n",
    "\n",
    "def get_glove_vectorized_data(X):\n",
    "    vectors = [get_mean_glove_vectors(word_tokenize(str(text))) for text in X['Product Title']]\n",
    "    valid_vectors = [vec for vec in vectors if vec is not None]\n",
    "    return np.concatenate(valid_vectors) if valid_vectors else np.array([])\n",
    "\n",
    "X_glove_array = get_glove_vectorized_data(df)\n",
    "knn_glove = NearestNeighbors(n_neighbors=15, metric='cosine')\n",
    "knn_glove.fit(X_glove_array)\n",
    "\n",
    "def find_similar_posts(input_text, vectorizer, knn_model, top_k=15):\n",
    "    if vectorizer == 'tfidf':\n",
    "        input_vector = tfidf_vectorizer.transform([input_text])\n",
    "    elif vectorizer == 'word2vec':\n",
    "        words = word_tokenize(input_text)\n",
    "        word_vectors = [word2vec_model.wv[word] for word in words if word in word2vec_model.wv]\n",
    "        if len(word_vectors) == 0:\n",
    "            return []\n",
    "        input_vector = np.mean(word_vectors, axis=0).reshape(1, -1)\n",
    "    elif vectorizer == 'glove':\n",
    "        input_vector = get_mean_glove_vectors(word_tokenize(input_text))\n",
    "        if input_vector is None:\n",
    "            return []\n",
    "\n",
    "    if vectorizer == 'tfidf':\n",
    "        _, indices = knn_tfidf.kneighbors(input_vector)\n",
    "    elif vectorizer == 'word2vec':\n",
    "        _, indices = knn_word2vec.kneighbors(input_vector)\n",
    "    elif vectorizer == 'glove':\n",
    "        _, indices = knn_glove.kneighbors(input_vector)\n",
    "    \n",
    "    similar_indices = indices.flatten()[:top_k]\n",
    "    similar_posts = [df.iloc[idx]['Product Title'] for idx in similar_indices]\n",
    "    \n",
    "    return similar_posts\n",
    "\n",
    "# Example usage\n",
    "input_text = \"purple phonecase\"\n",
    "similar_posts_tfidf = find_similar_posts(input_text, 'tfidf', knn_tfidf)\n",
    "similar_posts_word2vec = find_similar_posts(input_text, 'word2vec', knn_word2vec)\n",
    "similar_posts_glove = find_similar_posts(input_text, 'glove', knn_glove)\n",
    "\n",
    "print(\"Similar posts using TF-IDF:\")\n",
    "for post in similar_posts_tfidf:\n",
    "    print(post)\n",
    "\n",
    "print(\"\\nSimilar posts using Word2Vec:\")\n",
    "for post in similar_posts_word2vec:\n",
    "    print(post)\n",
    "\n",
    "print(\"\\nSimilar posts using GloVe:\")\n",
    "for post in similar_posts_glove:\n",
    "    print(post)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
